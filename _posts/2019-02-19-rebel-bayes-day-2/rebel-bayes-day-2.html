<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="radix" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Rebel Bayes Day 2</title>
  
  <meta property="description" itemprop="description" content="Prior beliefs about Bayesian statistics, updated by reading Statistical&#10;Rethinking by Richard McElreath."/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-02-19"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-02-19"/>
  <meta name="article:author" content="Duncan Garmonsway"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Rebel Bayes Day 2"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Prior beliefs about Bayesian statistics, updated by reading Statistical&#10;Rethinking by Richard McElreath."/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Rebel Bayes Day 2"/>
  <meta property="twitter:description" content="Prior beliefs about Bayesian statistics, updated by reading Statistical&#10;Rethinking by Richard McElreath."/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output"]}},"value":[{"type":"character","attributes":{},"value":["Rebel Bayes Day 2"]},{"type":"character","attributes":{},"value":["Prior beliefs about Bayesian statistics, updated by reading Statistical\nRethinking by Richard McElreath.\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name"]}},"value":[{"type":"character","attributes":{},"value":["Duncan Garmonsway"]}]}]},{"type":"character","attributes":{},"value":["February 19, 2019"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["radix::radix_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained"]}},"value":[{"type":"logical","attributes":{},"value":[false]}]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["rebel-bayes-day-2_files/bowser-1.9.3/bowser.min.js","rebel-bayes-day-2_files/distill-2.2.21/template.v2.js","rebel-bayes-day-2_files/jquery-1.11.3/jquery.min.js","rebel-bayes-day-2_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.radix-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="rebel-bayes-day-2_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="rebel-bayes-day-2_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="rebel-bayes-day-2_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="rebel-bayes-day-2_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Rebel Bayes Day 2","description":"Prior beliefs about Bayesian statistics, updated by reading Statistical\nRethinking by Richard McElreath.","authors":[{"author":"Duncan Garmonsway","authorURL":"#","affiliation":"&nbsp;","affiliationURL":"#"}],"publishedDate":"2019-02-19T00:00:00.000+00:00","citationText":"Garmonsway, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Rebel Bayes Day 2</h1>
<p>Prior beliefs about Bayesian statistics, updated by reading Statistical Rethinking by Richard McElreath.</p>
</div>

<div class="d-byline">
  
  Duncan Garmonsway
  
<br/>February 19, 2019
</div>

<div class="d-article">
<h2 id="reading-week">Reading week</h2>
<p>This week I am reading <a href="https://www.crcpress.com/Statistical-Rethinking-A-Bayesian-Course-with-Examples-in-R-and-Stan/McElreath/p/book/9781482253443">Statistical Rethinking</a> by Richard McElreath. Each day I post my prior beliefs about Bayesian Statistics, read a bit, and update them. See also <a href="https://nacnudus.github.io/duncangarmonsway/posts/2019-02-18-rebel-bayes-day-1/">Day 1</a>.</p>
<h2 id="prior-beliefs">Prior beliefs</h2>
<ol type="1">
<li>Inference is a mug’s game. Unless you have so much data that you don’t need stats, then you don’t have enough data to do stats.</li>
<li>Linear models combine values of features of a subject, to specify the parameters of a distribution, from which you draw a prediction of a value of a feature.</li>
<li>Distributions are normal because everything is either in one state or another, and the combination of many yes/no decisions is approximately normal.</li>
<li>Don’t you dare do this unless everything is independent and identically distributed.</li>
<li>A Bayesian linear model with uniform priors is exactly the same as a frequentist linear model.</li>
<li>The distributions of Bayesian parameter estimates are hard to interpret because they are all conditional on each other.</li>
<li><a href="https://nacnudus.github.io/duncangarmonsway/posts/2018-12-14-choose-a-priors-parameters/">It’s a pain to specify priors</a>.</li>
<li>Polynomial regression is the very devil because it will make false prophecies (overfitting) and polynomial relationships don’t occur in nature.</li>
<li>Categorical variables don’t have distributions – treat them as probabilities and pretend everything’s okay.</li>
<li>Ordinary Least Squares worked for my grandfather and if you have to use some other obscure method to make the data support you then you’re up to no good.</li>
<li>Even Bayes can’t protect you from your own willpower to find signal in noise.</li>
<li>Even Bayes can’t detect signals buried in ambiguous, indirect observation.</li>
<li>The AIC Information Criterion isn’t how acronyms work but it’s how Google search terms work.</li>
<li>Bayesians invented the BIC to be more punishing than the AIC and retake the moral high ground.</li>
<li><em>p</em>-values are contrived, essentially meaningless and nobody knows how they really work – oh look there’s an information criterion let’s use that!</li>
</ol>
<h3 id="undecided-from-previous-days">Undecided from previous days</h3>
<ol type="1">
<li>If computers had been invented before frequentist statistics, nobody would have invented frequentist statistics.</li>
<li>Bayesian A/B testing is the acceptable face of early stopping, aka ethical and pragmatic experimental design.</li>
<li>The Bayesian revival was masterminded by publishers to double their market by publishing Bayesian variants of everything.</li>
<li>Physicists worked out all the useful Bayesian methods ages ago but they have way cooler things to boast about.</li>
<li>WinBUGS is a leading indicator of a bad course.</li>
<li>STAN is the man.</li>
</ol>
<h2 id="new-data">New data</h2>
<h3 id="linear-models">4. Linear Models</h3>
<ul>
<li>“The Ptolemaic strategy is the same as a <em>Fourier series</em>”</li>
<li>“The model is incredibly wrong, yet makes quite good predictions.”</li>
</ul>
<h4 id="why-normal-distributions-are-normal">4.1 Why normal distributions are normal</h4>
<ul>
<li>“This is the sort of task that would be harrowing in a point-and-click interface.”</li>
<li>“eventually the most likely sum, in the sense that there are the most ways to realize it, will be a sum in which every fluctuation is canceled by another, a sum of zero (relative to the mean)”</li>
<li>“Multiplying small numbers is approximately the same as addition”</li>
<li>“Repeatedly adding finite fluctuations results in a distribution of sums that have shed all information about the underlying process, aside from mean and spread.”</li>
<li>“statistical models based on Gaussian distributions cannot reliably identify micro-process”</li>
<li>“[The Gaussian distribution] is the least surprising and least informative assumption to make.”</li>
<li>“Using a model is not equivalent to swearing an oath to it.”</li>
</ul>
<h4 id="a-language-for-describing-models">4.2 A language for describing models</h4>
<ul>
<li>“some procrustean model type, like regression or multiple regression or ANOVA or ANCOVA or such. These are all the same kind of model”</li>
</ul>
<h4 id="a-gaussian-model-of-height">4.3 A Gaussian model of height</h4>
<ul>
<li>“Yes, a distribution of distributions.”</li>
<li>“height is a sum of many small growth factors … a distribution of sums tends to converge to a Gaussian distribution”</li>
<li>“Gawking at the raw data, to try to decide how to model them, is usually not a good idea.”</li>
<li>“the empirical distribution needn’t be actually Gaussian in order to justify using a Gaussian likelihood.”</li>
<li>“in ignorance … the most conservative distribution to use is i.i.d.”</li>
<li>“<em>de Finetti’s theorem</em> … tells us that values which are exchangeable can be approximated by mixtures of i.i.d. distributions.”</li>
<li>“Markov chain Monte Carlo can use highly correlated sequential samples to estimate most any iid distribution we like.”</li>
<li>“89 is also a prime number, so if someone asks you to justify it, you can stare at them meaningfully and incant, ‘Because it is prime.’ That’s no worse justification than the conventional justification for 95%.”</li>
<li>“There’s so much data here that you’ll have to use pretty extreme priors to have any effect on inference.”</li>
<li>“Most non-Bayesian estimates implicitly use flat priors.”</li>
<li>“It’s sometimes useful to talk about the strength of a prior in terms of which data would lead to the same posterior distribution, beginning with a flat prior … the <span class="math inline">\(\mu \sim \mathrm{Normal}(178, 0.1)\)</span> is equivalent to having previously observed 100 heights with mean value 178.”</li>
</ul>
<h4 id="adding-a-predictor">4.4 Adding a predictor</h4>
<ul>
<li>“The linear model strategy … is to make the parameter for the mean of a Gaussian distribution, <span class="math inline">\(\mu\)</span>, into a linear function of the predictor variable and other, new parameters that we invent.”</li>
<li>“In this context, such a silly prior is harmless, because there is a lot of data.”</li>
<li>“Conventional Bayesian priors are <em>conservative</em>, relative to conventional non-Bayesian approaches.”</li>
<li>“<em>Posterior probabilities of parameter values describe the relative compatibility of different states of the world with the data, according to the model.</em>”</li>
<li>“The value of the intercept is frequently uninterpretable without also studying any <span class="math inline">\(\beta\)</span> parameters. That is why we need very weak priors for intercepts, in many cases.”</li>
<li>“tables of estimates are usually insufficient for understanding the information contained in the posterior distribution.”</li>
<li>“I have tried teaching such an analytical approach before, and it has always been disaster.”</li>
<li>“The fact that we can compute an expected value to the 10th decimal place does not imply that our inferences are precise to the 10th decimal place.”</li>
<li>“it’s possible to view the Gaussian likelihood as purely … a device for estimating the mean and variance of a variable”</li>
</ul>
<h4 id="polynomial-regression">4.5 Polynomial regression</h4>
<ul>
<li>“While this section teaches polynomial regression, in general it’s a bad thing to do. Why? Because polynomials are very hard to interpret. Better would be to have a more mechanistic model of the data, one that builds the non-linear relationship up from a principled beginning.”</li>
</ul>
<h3 id="multivariate-linear-models">5. Multivariate Linear Models</h3>
<ul>
<li>“There are even people would argue that cause does not really exist”</li>
<li>“Causal inference always depends upon unverifiable assumptions.”</li>
</ul>
<h4 id="spurious-association">5.1 Spurious association</h4>
<ul>
<li>“The point here isn’t to police language.”</li>
<li>“We’re not going to use the design matrix approach in this book. And in general you don’t need to.”</li>
<li>“To compute predictor residuals for either [predictor], we just use the other predictor to model it.”</li>
<li>“Luckily there are more general ways to plumb the mysteries of a model.”</li>
<li>“An extraordinary and evil degree of control over people would be necessary to really hold marriage rate constant while forcing everyone to marry at a later age.”</li>
<li>“Stats, huh, yeah what is it good for?”</li>
</ul>
<h4 id="masked-relationship">5.2 Masked relationship</h4>
<ul>
<li>“Milk is a huge investment, being much more expensive than gestation.”</li>
<li>“This kind of opaque error message is unfortunately the norm in R.”</li>
<li>“If you don’t get in there and modify some code, make some mistakes, and fix them, you’ll never grasp this stuff.”</li>
</ul>
<h4 id="when-adding-variables-hurts">5.3 When adding variables hurts</h4>
<ul>
<li>“it isn’t always true that highly correlated variables are completely redundant – other predictors might be correlated with only one of the pair”</li>
<li>“including post-treatment variables can actually mask the treatment itself.”</li>
<li>“In observational studies, it is harder to know [which variables are post-treatment]”</li>
</ul>
<h4 id="categorical-variables">5.4 Categorical variables</h4>
<p>No notes.</p>
<h4 id="ordinary-least-squares-and-lm">5.5 Ordinary least squares and <code>lm</code></h4>
<ul>
<li>“Instead of searching for the combination of parameter values that maximizes the posterior probability, OLS instead solves for the parameter values that minimize the sum of the squared residuals. It turns out that this procedure is often functionally equivalent”</li>
<li>“Gauss himself invented OLS as a method of computing Bayesian MAP estimates”</li>
<li>“Provided you are happy with flat priors, you’ll get the same estimates with <code>lm</code> that you got with <code>map</code>.”</li>
<li>“R is not a mind reader”</li>
</ul>
<h2 id="overfitting-regularization-and-information-criteria">6. Overfitting, Regularization, and Information Criteria</h2>
<ul>
<li>“The [Copernican] model was neither particularly harmonious nor more accurate than the geocentric model.”</li>
<li>“You’ll find that implementing them is much easier than understanding them.”</li>
<li>“BIC also requires flat priors and MAP estimates, although it’s not actually an ‘information criterion’.”</li>
<li>“Regardless, AIC has a clear and pragmatic interpretation under Bayesian probability”</li>
</ul>
<h4 id="the-problem-with-parameters">6.1 The problem with parameters</h4>
<ul>
<li>“model fitting can be considered a form of data compression”</li>
<li>“increasing bias often leads to better predictions”</li>
</ul>
<h4 id="information-theory-and-model-performance">6.2 Information theory and model performance</h4>
<ul>
<li>“like many successful fields, information theory has spawned a large number of bogus applications”</li>
<li>“<em>Information</em>: The reduction in uncertainty derived from learning an outcome.”</li>
<li>“when an event never happens, there’s no point in keeping it in the model.”</li>
<li>“Divergence depends upon direction.”</li>
<li>“while we don’t know where [the truth] is is, we can estimate how far apart [one model and the other] are, and which is closer to the target.”</li>
</ul>
<h4 id="regularization">6.3 Regularization</h4>
<ul>
<li>“One way to prevent a model from getting too excited by the training sample is to give it a skeptical prior.” <em>I’m not convinced. A skeptical prior becomes part of the information that the model encodes, so it is still trying to encode as much information as possible, you have just given it something else to compromise on</em>.</li>
<li>“try different priors and select the one that provides the smallest deviance on the test sample” <em>Uh-oh, now you’re encoding the test sample in the model specification. But everyone does this. Shaddup Duncan, it’s not worth it.</em></li>
<li>“Linear models in which the slope parameters use Gaussian priors, centered at zero, are sometimes known as ‘ridge regression’.”</li>
</ul>
<h4 id="information-criteria">6.4 Information Criteria</h4>
<ul>
<li>“information criteria … do not always assign the best expected <span class="math inline">\(D_{\mathrm{test}}\)</span> to the ‘true’ model.”</li>
<li>“DIC is essentially a version of AIC that is aware of informative priors.”</li>
<li>“Even better than the DIC is the Widely Applicable Information Criterion (WAIC) … it does not require a multivariate Gaussian posterior”</li>
<li>“Because WAIC requires splitting up the data into independent observations, it is sometimes hard to define” (e.g. time series)</li>
<li>“The choice between BIC or AIC (or neither!) is not about being Bayesian or not.”</li>
<li>“even when priors are weak and have no influence on estimates within models, priors can have a huge impact on comparisons between models” (when using BIC)</li>
<li>“AIC orders models in a way that approximates some forms of cross-validation, and WAIC is explicitly derived as an approximate Bayesian cross-validation.”</li>
<li>“once you start using multilevel models, ‘prediction’ is no longer uniquely defined, because the test sample can differ from the training sample in ways that forbid use of some of the parameter estimates.”</li>
</ul>
<h4 id="using-information-criteria">6.5 Using information criteria</h4>
<ul>
<li>“It is not possible to provide a principled threshold of difference that makes one model ‘significantly’ better than another, whatever that means”</li>
<li>“Barplots suck”</li>
<li>“it’s common to advise against trying every possible model”</li>
</ul>
<h2 id="updated-beliefs">Updated beliefs</h2>
<ol type="1">
<li>✓ Inference is a mug’s game. Unless you have so much data that you don’t need stats, then you don’t have enough data to do stats. <em>This is harsh, but it does seem that the only safe purpose of a model is prediction or to suggest other things to examine, and that any interpretation of parameters is unwise.</em></li>
<li>✓ Linear models combine values of features of a subject, to specify the parameters of a distribution, from which you draw a prediction of a value of a feature.</li>
<li>✓ Distributions are normal because everything is either in one state or another, and the combination of many yes/no decisions is approximately normal. <em>The text adds a lot more maths to this, but the gist is there.</em></li>
<li>✕ Don’t you dare do this unless everything is independent and identically distributed. <em>Apparently, like everything else, it might be okay as long as [litany of checks and balances]</em></li>
<li>✓ A Bayesian linear model with uniform priors is exactly the same as a freqentist linear model.</li>
<li>✓ The distributions of <del>Bayesian</del> parameter estimates are hard to interpret because they are all conditional on each other. <em>Not Bayes’ fault. The world is difficult to understand, and so are difficult models of it</em>.</li>
<li>✓ <a href="https://nacnudus.github.io/duncangarmonsway/posts/2018-12-14-choose-a-priors-parameters/">It’s a pain to specify priors</a>. <em>Not explicitly put in the text, but the author knows the distributions well enough to choose parameter estimates for the shape he wants, rather than have to work back from the shape to the parameters, or adjust after guessing.</em></li>
<li>✓ Polynomial regression is the very devil because it will make false prophecies (overfitting) and polynomial relationships don’t occur in nature. <em>Perhaps first-order ones do</em>.</li>
<li>? Categorical variables don’t have distributions – treat them as probabilities and pretend everything’s okay. <em>No logits were mentioned</em></li>
<li>✓ Ordinary Least Squares worked for my grandfather and if you have to use some other obscure method to make the data support you then you’re up to no good. <em>They turn out to be at the heart of Bayesian methods.</em></li>
<li>✓ Even Bayes can’t protect you from your own willpower to find signal in noise.</li>
<li>✓ Even Bayes can’t detect signals buried in ambiguous, indirect observation.</li>
<li>✓ The AIC Information Criterion isn’t how acronyms work but it’s how Google search terms work.</li>
<li>✕ Bayesians invented the BIC to be more punishing than the AIC and retake the moral high ground. <em>I was utterly wrong about this.</em></li>
<li>✓ <em>p</em>-values are contrived, essentially meaningless and nobody knows how they really work – oh look there’s an information criterion let’s use that! <em>I don’t see how using an information criterion to inform a decision is any more justifiable than using a </em>p<em>-value. They’re all rules of thumb</em></li>
<li>✕ The Bayesian revival was masterminded by publishers to double their market by publishing Bayesian variants of everything. <em>Bayesian methods seem more and more to be generalisations of frequentist methods.</em></li>
<li>✓ If computers had been invented before frequentist statistics, nobody would have invented frequentist statistics. <em>See above</em></li>
<li>✓ WinBUGS is a leading indicator of a bad course. <em>There’s no way this book could be translated to WinBUGS.</em></li>
</ol>
<h3 id="still-undecided-from-previous-days">Still undecided from previous days</h3>
<ol type="1">
<li>? Bayesian A/B testing is the acceptable face of early stopping, aka ethical and pragmatic experimental design.</li>
<li>? Physicists worked out all the useful Bayesian methods ages ago but they have way cooler things to boast about.</li>
<li>? STAN is the man.</li>
</ol>
<h2 id="critics-choice">Critic’s Choice</h2>
<p>My new favourite illustration of overfitting is the plot of different polynomial regressions fitted to leave-one-out samples of one data set (p173). I like the idea of talking about the strength of a prior in terms of which data would lead to the same posterior distribution. I also like the idea of using the Gaussian likelihood merely to estimate the mean and variance of a variable.</p>
<p>The general impression of these chapters is that Bayesian methods are the same as frequentist ones, with the following differences:</p>
<ul>
<li>Parameters at least at the top level are drawn from distributions, and the parameters of <em>those</em> distributions might be as well, but eventually at the bottom the parameters are fixed.</li>
<li>Sampling replaces equations derived analytically.</li>
<li>The pedagogy is better – ommission of smug analytical proofs and abstract rules leaves room for more interesting topics like how to check that a model is reasonable.</li>
</ul>
<p>The usual limitations of data and modelling remain.</p>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
